{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96d40783",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\warda\\anaconda3\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\warda\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.3)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.3.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (16.0.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.22.4)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.54.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.22.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\warda\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.0.3 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.9.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.17.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.12.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\warda\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6301f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2706a2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c4bc941",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfe29d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "131476dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a84c5877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 67s 37ms/step - loss: 1.5168 - accuracy: 0.4449 - val_loss: 1.2591 - val_accuracy: 0.5450\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 1.1730 - accuracy: 0.5836 - val_loss: 1.1113 - val_accuracy: 0.6054\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 1.0188 - accuracy: 0.6424 - val_loss: 1.0124 - val_accuracy: 0.6355\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 0.9139 - accuracy: 0.6787 - val_loss: 0.9542 - val_accuracy: 0.6625\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.8430 - accuracy: 0.7049 - val_loss: 0.9147 - val_accuracy: 0.6839\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 1497s 958ms/step - loss: 0.7774 - accuracy: 0.7303 - val_loss: 0.8783 - val_accuracy: 0.6935\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 0.7360 - accuracy: 0.7424 - val_loss: 0.8836 - val_accuracy: 0.6937\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 40s 26ms/step - loss: 0.6833 - accuracy: 0.7597 - val_loss: 0.8899 - val_accuracy: 0.6966\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.6464 - accuracy: 0.7741 - val_loss: 0.8425 - val_accuracy: 0.7169\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 0.6054 - accuracy: 0.7855 - val_loss: 0.8824 - val_accuracy: 0.7108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x184dffab910>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d243f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 76s 48ms/step - loss: 1.5941 - accuracy: 0.4115 - val_loss: 1.2875 - val_accuracy: 0.5317\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.2914 - accuracy: 0.5349 - val_loss: 1.1674 - val_accuracy: 0.5883\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 1.1615 - accuracy: 0.5874 - val_loss: 1.0143 - val_accuracy: 0.6479\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 1.0860 - accuracy: 0.6125 - val_loss: 1.0182 - val_accuracy: 0.6389\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 1.0126 - accuracy: 0.6406 - val_loss: 0.9583 - val_accuracy: 0.6673\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 0.9622 - accuracy: 0.6587 - val_loss: 0.9046 - val_accuracy: 0.6804\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.9298 - accuracy: 0.6703 - val_loss: 0.9136 - val_accuracy: 0.6812\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 0.8915 - accuracy: 0.6826 - val_loss: 0.8628 - val_accuracy: 0.6973\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.8621 - accuracy: 0.6979 - val_loss: 0.8390 - val_accuracy: 0.7085\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.8373 - accuracy: 0.7041 - val_loss: 0.8227 - val_accuracy: 0.7167\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.8151 - accuracy: 0.7144 - val_loss: 0.8372 - val_accuracy: 0.7058\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.7910 - accuracy: 0.7214 - val_loss: 0.7888 - val_accuracy: 0.7274\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.7809 - accuracy: 0.7267 - val_loss: 0.8030 - val_accuracy: 0.7188\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.7599 - accuracy: 0.7311 - val_loss: 0.7682 - val_accuracy: 0.7377\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 0.7441 - accuracy: 0.7373 - val_loss: 0.7791 - val_accuracy: 0.7312\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 0.7256 - accuracy: 0.7451 - val_loss: 0.7876 - val_accuracy: 0.7330\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.7219 - accuracy: 0.7475 - val_loss: 0.7585 - val_accuracy: 0.7390\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.7051 - accuracy: 0.7503 - val_loss: 0.7779 - val_accuracy: 0.7301\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.6876 - accuracy: 0.7569 - val_loss: 0.7424 - val_accuracy: 0.7452\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 0.6758 - accuracy: 0.7589 - val_loss: 0.8035 - val_accuracy: 0.7229\n"
     ]
    }
   ],
   "source": [
    "#Here are some hyperparameters that you can experiment with to improve the performance of the model:\n",
    "# Change the number of convolutional layers and filters in each layer.\n",
    "# Increase or decrease the size of the filters.\n",
    "# Add dropout layers to prevent overfitting.\n",
    "# Change the number of fully connected layers and neurons in each layer.\n",
    "# Increase or decrease the learning rate of the optimizer.\n",
    "# Train the model for more epochs or use early stopping to prevent overfitting.\n",
    "# Here's an example of how you can train the model for more epochs and add a dropout layer:\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=20, validation_data=(x_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dd23779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 3s - loss: 0.8035 - accuracy: 0.7229 - 3s/epoch - 10ms/step\n",
      "Test accuracy: 0.7228999733924866\n",
      "313/313 [==============================] - 3s 9ms/step\n",
      "[[805  17  29  13  16   1  16   9  81  13]\n",
      " [ 27 887   2   1   4   0  15   3  19  42]\n",
      " [ 79   8 609  33 109  23  95  26  13   5]\n",
      " [ 31   9  93 460 111  77 145  44  16  14]\n",
      " [ 22   2  56  20 770   5  83  29  12   1]\n",
      " [ 17   4  83 181  91 463  74  73   6   8]\n",
      " [ 11   2  31  26  23   5 892   2   7   1]\n",
      " [ 24   3  35  32 128  17  11 734   4  12]\n",
      " [ 67  35   7  11   7   0   7   3 851  12]\n",
      " [ 44 100  10  11   8   0  13   9  47 758]]\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test accuracy:', test_acc)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "y_pred = np.argmax(model.predict(x_test), axis=-1)\n",
    "cm = confusion_matrix(np.argmax(y_test, axis=-1), y_pred)\n",
    "\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4873f8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are some techniques you can experiment with to fine-tune the model:\n",
    "\n",
    "# Data augmentation: Generate additional training data by applying transformations such as rotation, scaling, and flipping to the existing images. This can help the model generalize better to new data and prevent overfitting.\n",
    "\n",
    "# Dropout: Add dropout layers to the model to randomly drop out some neurons during training, which can prevent overfitting.\n",
    "\n",
    "# Batch normalization: Normalize the activations of the previous layer at each batch, which can help the model train faster and generalize better.\n",
    "\n",
    "# Transfer learning: Use a pre-trained model as a starting point and fine-tune it on the CIFAR-10 dataset. This can help the model learn better features and improve its performance.\n",
    "\n",
    "#This code uses the ImageDataGenerator class from Keras to apply data augmentation to the training set. It also loads a pre-trained VGG16 model and freezes its layers, then adds a few fully connected layers on top of it. Finally, it trains the model on the augmented data for 50 epochs.\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# Define data augmentation pipeline\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_datagen.fit(x_train)\n",
    "\n",
    "# Load pre-trained model and fine-tune on CIFAR-10\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    BatchNormalization(),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_datagen.flow(x_train, y_train, batch_size=32),\n",
    "                    epochs=10,\n",
    "                    validation_data=(x_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcb2ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
